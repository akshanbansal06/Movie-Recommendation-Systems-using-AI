{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akshanbansal06/Movie-Recommendation-Systems-using-AI/blob/main/MLProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bJeGicnF2bUA"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i0uz6bpf-eYL"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "aio = pd.read_csv('drive/MyDrive/allinone.csv')\n",
        "df = pd.DataFrame(aio)\n",
        "\n",
        "genre_list = ['action', 'adult', 'adventure', 'animation', 'biography',\n",
        "              'crime', 'fantasy' ,'film-noir' , 'game-show', 'history',\n",
        "              'horror', 'music' ,'musical' ,'mystery', 'reality-tv',\n",
        "              'sci-fi','sport','thriller','war','western']\n",
        "\n",
        "''' for genre in genre_list:\n",
        "    data = pd.read_csv(genre+\".csv\")\n",
        "    df = pd.concat([df, data], axis=0)\n",
        "df.to_csv('allinone.csv', index=False) '''\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uQKViivRPPZu"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FF67HEeHCIz8"
      },
      "outputs": [],
      "source": [
        "recol = ['id','duration','votes','gross_income', 'directors_id', 'directors_name', 'stars_id', 'certificate']\n",
        "for r in recol:\n",
        "  del df[r]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QRdYS91UVBFU"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZVNIgds3VMs_"
      },
      "outputs": [],
      "source": [
        "df = df.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1KgUmsmYFEzN"
      },
      "outputs": [],
      "source": [
        "df = df.drop_duplicates(subset=['name'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i = df[df[\"rating\"] <= 6].index\n",
        "df.drop( i, inplace=True)"
      ],
      "metadata": {
        "id": "Igc2NEj1f9zO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "genre_list = ['Biography','Film-Noir' , 'History','Music' ,'Musical' ,'War','Western','Short', 'Game-Show', 'Sport', 'Adult', 'Reality-TV']\n",
        "for y in genre_list:\n",
        "  mask = df.genre.apply(lambda x: y in x)\n",
        "  i = df[mask].index\n",
        "  df.drop(i, inplace=True)"
      ],
      "metadata": {
        "id": "6MGpyenYhFv5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OUy9kFfaLkAx"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ry = []\n",
        "for i in range(1920, 1990):\n",
        "  ry.append(str(i))\n",
        "ry.append(\"Video\")\n",
        "for y in ry:\n",
        "  i = df[df.year.apply(lambda x:  y in x)].index\n",
        "  df.drop(i, inplace=True)"
      ],
      "metadata": {
        "id": "22m8G2UWsMud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.sort_values(by=['rating'], ascending=False)"
      ],
      "metadata": {
        "id": "jIcWnlN49IdG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g0thC_crXPhg"
      },
      "outputs": [],
      "source": [
        "df.reset_index(drop = True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "odf = df"
      ],
      "metadata": {
        "id": "NoDlpZgFox7f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#"
      ],
      "metadata": {
        "id": "MKgF84uuOdsE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#"
      ],
      "metadata": {
        "id": "g_nCKSZ-Odg1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#"
      ],
      "metadata": {
        "id": "AZ1XV9DhOdTZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#"
      ],
      "metadata": {
        "id": "4BOOH0w6OdGo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#"
      ],
      "metadata": {
        "id": "0nWcaqI_Oc0q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For cosine similarity based recommending system."
      ],
      "metadata": {
        "id": "Gu4YE477ORs4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "from scipy.spatial.distance import cosine\n",
        "import heapq\n",
        "import numpy as np\n",
        "\n",
        "df = odf.sample(1000)\n",
        "\n",
        "genre_list = ['Action', 'Adventure', 'Animation', 'Crime', 'Fantasy', 'Horror', 'Mystery', 'Sci-Fi', 'Thriller', 'Drama', 'Romance', 'Family', 'Comedy']\n",
        "num_users = 20\n",
        "\n",
        "users = {'user': list(range(1, num_users + 1)), 'mts': []}\n",
        "for _ in range(num_users):\n",
        "    random_movies = random.sample(df['name'].tolist(), 20)\n",
        "    users['mts'].append(random_movies)\n",
        "\n",
        "ugv = []\n",
        "for user_movies in users['mts']:\n",
        "    user_genre_vector = [0] * len(genre_list)\n",
        "    for movie in user_movies:\n",
        "        movie_genres = df[df['name'] == movie]['genre'].values[0].split(', ')\n",
        "        for i, genre in enumerate(genre_list):\n",
        "            if genre in movie_genres:\n",
        "                user_genre_vector[i] += 1\n",
        "    ugv.append(user_genre_vector)\n",
        "\n",
        "ugvdf = pd.DataFrame(ugv)\n",
        "\n",
        "gv = []\n",
        "for genres in df['genre'].str.split(', '):\n",
        "    movie_genre_vector = [1 if genre in genres else 0 for genre in genre_list]\n",
        "    gv.append(movie_genre_vector)\n",
        "\n",
        "gvdf = pd.DataFrame(gv)\n",
        "\n",
        "ugvm = ugvdf.to_numpy()\n",
        "gvm = gvdf.to_numpy()\n"
      ],
      "metadata": {
        "id": "zyVol_slV8zy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rm = []\n",
        "cvls = []\n",
        "\n",
        "for u in ugvm:\n",
        "    prm = []\n",
        "    t10 = []\n",
        "    cvl = []\n",
        "\n",
        "    for mi in range(len(gvm)):\n",
        "        cs = 1 - cosine(u, gvm[mi])\n",
        "        cs *= 100\n",
        "        heapq.heappush(t10, (cs, df['name'].loc[df.index[mi]]))\n",
        "\n",
        "    t10 = heapq.nlargest(10, t10)\n",
        "    t10n = [name for cs, name in t10]\n",
        "    prm.extend(t10n)\n",
        "\n",
        "    t10cv = [cs for cs, name in t10]\n",
        "    cvl.append(t10cv)\n",
        "    accu = np.mean(cvl)\n",
        "    cvls.append(accu)\n",
        "\n",
        "    rm.append(prm)\n",
        "\n",
        "rmdf = pd.DataFrame(rm).T.head(20).T\n",
        "accuracy = np.mean(cvls)\n"
      ],
      "metadata": {
        "id": "jqaxLmWydOkm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rmdf"
      ],
      "metadata": {
        "id": "CFenVNjiezms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy"
      ],
      "metadata": {
        "id": "EVyi6VBle0_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#"
      ],
      "metadata": {
        "id": "A_Jk2CWO2xqS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#"
      ],
      "metadata": {
        "id": "FOdw06HY2xqc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#"
      ],
      "metadata": {
        "id": "y9kISEs92xqd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#"
      ],
      "metadata": {
        "id": "CdEMe_pa2xqd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#"
      ],
      "metadata": {
        "id": "6PhvKXeo2xqd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Common Code"
      ],
      "metadata": {
        "id": "PB1dI4NH2nOe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "movie_data = odf.sample(1000)\n",
        "recol = ['stars_name', 'description']\n",
        "for r in recol:\n",
        "  del movie_data[r]"
      ],
      "metadata": {
        "id": "XLX5k5rU-FMc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "\n",
        "users = {'user_id': [], 'movie_list': []}\n",
        "users2 = {'user_id': [], 'genre': []}\n",
        "ui = []\n",
        "ali = []\n",
        "bli = []\n",
        "yli = []\n",
        "mts = movie_data['name'].values.tolist()\n",
        "gts = movie_data['genre'].values.tolist()\n",
        "\n",
        "for i in range(len(mts)-1):\n",
        "    xli = [mts[i], gts[i]]\n",
        "    yli.append(xli)\n",
        "\n",
        "for i in range(1, 1001):\n",
        "    li = random.sample(yli, 50)\n",
        "    ui.append(i)\n",
        "    mli = [k[0] for k in li]\n",
        "    nli = [k[1] for k in li]\n",
        "\n",
        "    gsli = [genre.split(\", \") for genre in nli]\n",
        "    flattened_genres = [item for sublist in gsli for item in sublist if item != 'Drama']\n",
        "    ec = Counter(flattened_genres)\n",
        "    t3 = ec.most_common(3)\n",
        "    mt = [e for e, count in t3]\n",
        "    rls = ','.join(mt)\n",
        "    ali.append(mli)\n",
        "    bli.append(rls)\n",
        "\n",
        "users['user_id'] = ui\n",
        "users['movie_list'] = ali\n",
        "users2['user_id'] = ui\n",
        "users2['genre'] = bli\n",
        "\n",
        "mudf = pd.DataFrame.from_dict(users)\n",
        "gudf = pd.DataFrame.from_dict(users2)\n"
      ],
      "metadata": {
        "id": "FIIhpzTt4ggz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mudf"
      ],
      "metadata": {
        "id": "Eq7QRMuk9dd0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gudf"
      ],
      "metadata": {
        "id": "FTlRDyhOBChd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "our_def_acc = []"
      ],
      "metadata": {
        "id": "3d48Fruc5vl8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "our_def_acc.append(accuracy)"
      ],
      "metadata": {
        "id": "P7O8CBcO6IOH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#"
      ],
      "metadata": {
        "id": "ILuTyMQ1-4Dd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#"
      ],
      "metadata": {
        "id": "YtXXrAX4-4Dm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#"
      ],
      "metadata": {
        "id": "iQoPgOaz-4Dm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#"
      ],
      "metadata": {
        "id": "gbD6zY13-4Dm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using CNN"
      ],
      "metadata": {
        "id": "8_he4YblJckC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, Conv1D, MaxPooling1D, Flatten, Dense\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "YG5MxCVasNVH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_genre_data = gudf[['user_id', 'genre']]\n",
        "train_data, test_data = train_test_split(user_genre_data, test_size=0.2, random_state=42)\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(movie_data['name'])\n",
        "num_words = len(tokenizer.word_index) + 1\n",
        "max_sequence_length = 100\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(movie_data['name'])\n",
        "X = pad_sequences(sequences, maxlen=max_sequence_length)\n",
        "\n",
        "user_data = gudf\n",
        "\n",
        "mlb = MultiLabelBinarizer()\n",
        "xgdf = user_data['genre'].apply(lambda x: x.split(','))\n",
        "genre_matrix = mlb.fit_transform(xgdf)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(num_words, 100, input_length=max_sequence_length))\n",
        "model.add(Conv1D(128, 5, activation='relu'))\n",
        "model.add(MaxPooling1D(5))\n",
        "model.add(Conv1D(128, 5, activation='relu'))\n",
        "model.add(MaxPooling1D(5))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(mlb.classes_.shape[0], activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.fit(X, genre_matrix, epochs=10, batch_size=32)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PqfX8ENq21Zk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def recommend_movies(user_movie_list, num_recommendations=10):\n",
        "\n",
        "    user_sequences = tokenizer.texts_to_sequences(user_movie_list)\n",
        "    user_input = pad_sequences(user_sequences, maxlen=max_sequence_length)\n",
        "\n",
        "    predicted_genre_probs = model.predict(user_input)\n",
        "\n",
        "    user_genre_profile = np.mean(predicted_genre_probs, axis=0)\n",
        "\n",
        "    similarity_scores = np.dot(predicted_genre_probs, user_genre_profile)\n",
        "\n",
        "    recommended_movie_indices = np.argsort(similarity_scores)[::-1][:num_recommendations]\n",
        "    recommended_movies = movie_data.iloc[recommended_movie_indices]['name'].tolist()\n",
        "\n",
        "    min_score = np.min(similarity_scores)\n",
        "    max_score = np.max(similarity_scores)\n",
        "    scaled_similarity_scores = 100 * (similarity_scores - min_score) / (max_score - min_score)\n",
        "    top_similarity_scores = scaled_similarity_scores[recommended_movie_indices]\n",
        "    mean_similarity_score = np.mean(top_similarity_scores)\n",
        "\n",
        "    return recommended_movies, mean_similarity_score"
      ],
      "metadata": {
        "id": "-Tu7SrcNkqTr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uml = mudf.loc[mudf['user_id'] == 1, 'movie_list'].iloc[0]\n",
        "rm = recommend_movies(uml)\n",
        "print(rm)"
      ],
      "metadata": {
        "id": "DmvaMbgFFJbk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rms = []\n",
        "acc = []\n",
        "for i in range(1,1001):\n",
        "  ui = i\n",
        "  uml = mudf.loc[mudf['user_id'] == ui, 'movie_list'].iloc[0]\n",
        "  print(i, \"/1000\")\n",
        "  rm = recommend_movies(uml)\n",
        "  rms.append(rm[0])\n",
        "  acc.append(rm[1])\n",
        "\n",
        "accuracy = np.mean(acc)\n",
        "\n",
        "rmdf = pd.DataFrame(rms)"
      ],
      "metadata": {
        "id": "2tn5YVjG21Q6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rmdf"
      ],
      "metadata": {
        "id": "QzZqaJL1ovis"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy"
      ],
      "metadata": {
        "id": "qiB52VOT0eTT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "our_def_acc.append(accuracy)"
      ],
      "metadata": {
        "id": "1vLYUqWT57Zd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#"
      ],
      "metadata": {
        "id": "BBcMUhsr2ykJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#"
      ],
      "metadata": {
        "id": "WSPlk8-q2ykJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#"
      ],
      "metadata": {
        "id": "eYyYRH5K2ykK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#"
      ],
      "metadata": {
        "id": "0Hr_Stch2ykK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#"
      ],
      "metadata": {
        "id": "8nlH6TQn-LYw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using RNN"
      ],
      "metadata": {
        "id": "f_1QW3Cu-LZC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, LSTM, Dense\n",
        "from sklearn.preprocessing import MultiLabelBinarizer"
      ],
      "metadata": {
        "id": "66RIT7PB-LZG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_genre_data = gudf[['user_id', 'genre']]\n",
        "train_data, test_data = train_test_split(user_genre_data, test_size=0.2, random_state=42)\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(movie_data['name'])\n",
        "num_words = len(tokenizer.word_index) + 1\n",
        "max_sequence_length = 100\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(movie_data['name'])\n",
        "X = pad_sequences(sequences, maxlen=max_sequence_length)\n",
        "\n",
        "user_data = gudf\n",
        "\n",
        "mlb = MultiLabelBinarizer()\n",
        "xgdf = user_data['genre'].apply(lambda x: x.split(','))\n",
        "genre_matrix = mlb.fit_transform(xgdf)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(num_words, 100, input_length=max_sequence_length))\n",
        "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(mlb.classes_.shape[0], activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.fit(X, genre_matrix, epochs=10, batch_size=32)\n"
      ],
      "metadata": {
        "id": "j5R5DVFI-LZH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def recommend_movies(user_movie_list, num_recommendations=10):\n",
        "\n",
        "    user_sequences = tokenizer.texts_to_sequences(user_movie_list)\n",
        "    user_input = pad_sequences(user_sequences, maxlen=max_sequence_length)\n",
        "\n",
        "    predicted_genre_probs = model.predict(user_input)\n",
        "\n",
        "    user_genre_profile = np.mean(predicted_genre_probs, axis=0)\n",
        "\n",
        "    similarity_scores = np.dot(predicted_genre_probs, user_genre_profile)\n",
        "\n",
        "    recommended_movie_indices = np.argsort(similarity_scores)[::-1][:num_recommendations]\n",
        "    recommended_movies = movie_data.iloc[recommended_movie_indices]['name'].tolist()\n",
        "\n",
        "\n",
        "    min_score = np.min(similarity_scores)\n",
        "    max_score = np.max(similarity_scores)\n",
        "    scaled_similarity_scores = 100 * (similarity_scores - min_score) / (max_score - min_score)\n",
        "    top_similarity_scores = scaled_similarity_scores[recommended_movie_indices]\n",
        "    mean_similarity_score = np.mean(top_similarity_scores)\n",
        "\n",
        "    return recommended_movies, mean_similarity_score\n"
      ],
      "metadata": {
        "id": "ChLo1R7W-LZH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uml = mudf.loc[mudf['user_id'] == 1, 'movie_list'].iloc[0]\n",
        "rm = recommend_movies(uml)\n",
        "print(rm)"
      ],
      "metadata": {
        "id": "HkXCyA-i-LZI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rms = []\n",
        "acc = []\n",
        "for i in range(1,1001):\n",
        "  ui = i\n",
        "  uml = mudf.loc[mudf['user_id'] == ui, 'movie_list'].iloc[0]\n",
        "  print(i, \"/1000\")\n",
        "  rm = recommend_movies(uml)\n",
        "  rms.append(rm[0])\n",
        "  acc.append(rm[1])\n",
        "\n",
        "accuracy = np.mean(acc)\n",
        "\n",
        "rmdf = pd.DataFrame(rms)"
      ],
      "metadata": {
        "id": "lPnxABRZ-LZI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rmdf"
      ],
      "metadata": {
        "id": "laA2aes2-LZI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy"
      ],
      "metadata": {
        "id": "U_SPC45C-LZI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "our_def_acc.append(accuracy)"
      ],
      "metadata": {
        "id": "pH8PE44_6cNk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#"
      ],
      "metadata": {
        "id": "SZvHor0s-LZJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#"
      ],
      "metadata": {
        "id": "ZDKnYOkX-LZK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#"
      ],
      "metadata": {
        "id": "ACi8tChF-LZK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#"
      ],
      "metadata": {
        "id": "JYDOAza6-LZL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#"
      ],
      "metadata": {
        "id": "eyWTzUBrJlRH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#"
      ],
      "metadata": {
        "id": "ycfZF3BDJlRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#"
      ],
      "metadata": {
        "id": "PJgGWOeFJlRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#"
      ],
      "metadata": {
        "id": "sbo7j3EAJlRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using ANN"
      ],
      "metadata": {
        "id": "2unjYkJzJlRR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, Flatten, Dense\n",
        "from sklearn.preprocessing import MultiLabelBinarizer"
      ],
      "metadata": {
        "id": "Fem9Qxz6JlRR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_genre_data = gudf[['user_id', 'genre']]\n",
        "train_data, test_data = train_test_split(user_genre_data, test_size=0.2, random_state=42)\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(movie_data['name'])\n",
        "num_words = len(tokenizer.word_index) + 1\n",
        "max_sequence_length = 100\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(movie_data['name'])\n",
        "X = pad_sequences(sequences, maxlen=max_sequence_length)\n",
        "\n",
        "user_data = gudf\n",
        "\n",
        "mlb = MultiLabelBinarizer()\n",
        "xgdf = user_data['genre'].apply(lambda x: x.split(','))\n",
        "genre_matrix = mlb.fit_transform(xgdf)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(num_words, 100, input_length=max_sequence_length))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(genre_matrix.shape[1], activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "model.fit(X, genre_matrix, epochs=10, batch_size=32)"
      ],
      "metadata": {
        "id": "ovx8vDEkJlRR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def recommend_movies(user_movie_list, num_recommendations=10):\n",
        "\n",
        "    user_sequences = tokenizer.texts_to_sequences(user_movie_list)\n",
        "    user_input = pad_sequences(user_sequences, maxlen=max_sequence_length)\n",
        "\n",
        "    predicted_genre_probs = model.predict(user_input)\n",
        "\n",
        "    user_genre_profile = np.mean(predicted_genre_probs, axis=0)\n",
        "\n",
        "    similarity_scores = np.dot(predicted_genre_probs, user_genre_profile)\n",
        "\n",
        "    recommended_movie_indices = np.argsort(similarity_scores)[::-1][:num_recommendations]\n",
        "    recommended_movies = movie_data.iloc[recommended_movie_indices]['name'].tolist()\n",
        "\n",
        "\n",
        "    min_score = np.min(similarity_scores)\n",
        "    max_score = np.max(similarity_scores)\n",
        "    scaled_similarity_scores = 100 * (similarity_scores - min_score) / (max_score - min_score)\n",
        "    top_similarity_scores = scaled_similarity_scores[recommended_movie_indices]\n",
        "    mean_similarity_score = np.mean(top_similarity_scores)\n",
        "\n",
        "    return recommended_movies, mean_similarity_score\n"
      ],
      "metadata": {
        "id": "qTsAhZ9bJlRS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uml = mudf.loc[mudf['user_id'] == 1, 'movie_list'].iloc[0]\n",
        "rm = recommend_movies(uml)\n",
        "print(rm)"
      ],
      "metadata": {
        "id": "IWIhePvgJlRS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rms = []\n",
        "acc = []\n",
        "for i in range(1,1001):\n",
        "  ui = i\n",
        "  uml = mudf.loc[mudf['user_id'] == ui, 'movie_list'].iloc[0]\n",
        "  print(i, \"/1000\")\n",
        "  rm = recommend_movies(uml)\n",
        "  rms.append(rm[0])\n",
        "  acc.append(rm[1])\n",
        "\n",
        "accuracy = np.mean(acc)\n",
        "\n",
        "rmdf = pd.DataFrame(rms)"
      ],
      "metadata": {
        "id": "Gk5kJGxxJlRS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rmdf"
      ],
      "metadata": {
        "id": "XHis7fKWJlRT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy"
      ],
      "metadata": {
        "id": "3-gPC_03JlRT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "our_def_acc.append(accuracy)"
      ],
      "metadata": {
        "id": "_d2vue3D6rmc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#"
      ],
      "metadata": {
        "id": "wOs56JpaJlRT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#"
      ],
      "metadata": {
        "id": "GuJaCRVjJlRT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#"
      ],
      "metadata": {
        "id": "LgnGD2dIKpKR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#"
      ],
      "metadata": {
        "id": "d7tok1pWKpKb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#"
      ],
      "metadata": {
        "id": "3LXhU5-fKpKc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using RBFNN"
      ],
      "metadata": {
        "id": "AnNIn_B2KpKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn.preprocessing import MultiLabelBinarizer"
      ],
      "metadata": {
        "id": "g_fkkC3yKpKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_genre_data = gudf[['user_id', 'genre']]\n",
        "train_data, test_data = train_test_split(user_genre_data, test_size=0.2, random_state=42)\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(movie_data['name'])\n",
        "num_words = len(tokenizer.word_index) + 1\n",
        "max_sequence_length = 100\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(movie_data['name'])\n",
        "X = pad_sequences(sequences, maxlen=max_sequence_length)\n",
        "\n",
        "user_data = gudf\n",
        "\n",
        "mlb = MultiLabelBinarizer()\n",
        "xgdf = user_data['genre'].apply(lambda x: x.split(','))\n",
        "genre_matrix = mlb.fit_transform(xgdf)\n",
        "\n",
        "import keras.backend as K\n",
        "\n",
        "def rbf_activation(x):\n",
        "    return K.exp(-1 * K.square(x))\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_dim=max_sequence_length, activation=rbf_activation))\n",
        "model.add(Dense(genre_matrix.shape[1], activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.fit(X, genre_matrix, epochs=10, batch_size=32)\n"
      ],
      "metadata": {
        "id": "G5q2kQqNKpKf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def recommend_movies(user_movie_list, num_recommendations=10):\n",
        "\n",
        "    user_sequences = tokenizer.texts_to_sequences(user_movie_list)\n",
        "    user_input = pad_sequences(user_sequences, maxlen=max_sequence_length)\n",
        "\n",
        "    predicted_genre_probs = model.predict(user_input)\n",
        "\n",
        "    user_genre_profile = np.mean(predicted_genre_probs, axis=0)\n",
        "\n",
        "    similarity_scores = np.dot(predicted_genre_probs, user_genre_profile)\n",
        "\n",
        "    recommended_movie_indices = np.argsort(similarity_scores)[::-1][:num_recommendations]\n",
        "    recommended_movies = movie_data.iloc[recommended_movie_indices]['name'].tolist()\n",
        "\n",
        "\n",
        "    min_score = np.min(similarity_scores)\n",
        "    max_score = np.max(similarity_scores)\n",
        "    scaled_similarity_scores = 100 * (similarity_scores - min_score) / (max_score - min_score)\n",
        "    top_similarity_scores = scaled_similarity_scores[recommended_movie_indices]\n",
        "    mean_similarity_score = np.mean(top_similarity_scores)\n",
        "\n",
        "    return recommended_movies, mean_similarity_score"
      ],
      "metadata": {
        "id": "E9OhHgi4KpKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uml = mudf.loc[mudf['user_id'] == 1, 'movie_list'].iloc[0]\n",
        "rm = recommend_movies(uml)\n",
        "print(rm)"
      ],
      "metadata": {
        "id": "UAZRuYF4KpKm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rms = []\n",
        "acc = []\n",
        "for i in range(1,1001):\n",
        "  ui = i\n",
        "  uml = mudf.loc[mudf['user_id'] == ui, 'movie_list'].iloc[0]\n",
        "  print(i, \"/1000\")\n",
        "  rm = recommend_movies(uml)\n",
        "  rms.append(rm[0])\n",
        "  acc.append(rm[1])\n",
        "\n",
        "accuracy = np.mean(acc)\n",
        "\n",
        "rmdf = pd.DataFrame(rms)"
      ],
      "metadata": {
        "id": "43kH1LA2KpKn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rmdf"
      ],
      "metadata": {
        "id": "w42nYWhIKpKp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy"
      ],
      "metadata": {
        "id": "G6eihrKtKpKq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "our_def_acc.append(accuracy)"
      ],
      "metadata": {
        "id": "Ycwmb8WX6t-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(our_def_acc)"
      ],
      "metadata": {
        "id": "c6z8t1L26vo2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import subprocess\n",
        "\n",
        "models = ['Cosine', 'CNN', 'RNN', 'ANN', 'RBFNN']\n",
        "plt.plot(models, our_def_acc, label='Performance', marker='o')\n",
        "\n",
        "plt.xlabel('Models')\n",
        "plt.ylabel('Performance')\n",
        "plt.legend()\n",
        "plt.title('Performance Comparison')\n",
        "\n",
        "plot_filename = 'accuracy_plot.png'\n",
        "\n",
        "plt.savefig(plot_filename)\n",
        "\n",
        "plt.close()\n",
        "\n",
        "subprocess.Popen(['open', plot_filename])\n",
        "\n",
        "input(\"Press Enter to continue...\")\n",
        "\n",
        "os.remove(plot_filename)\n"
      ],
      "metadata": {
        "id": "CWzhuod6L77h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#"
      ],
      "metadata": {
        "id": "veGNxWf7KpKq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#"
      ],
      "metadata": {
        "id": "acbLTk5ZKpKq"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}